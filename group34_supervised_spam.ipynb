{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox_dkPVQV8g_"
      },
      "source": [
        "### **NLP Final Project**\n",
        "#### **Spam and Sentiment Email Analysis: Spam Bi-LSTM Supervised Learning**\n",
        "\n",
        "Wilson Neira"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-53iXbvV8hC"
      },
      "source": [
        "##### **1. Import**\n",
        "* Import libraries needed for deep learning and text sequence preparation with TensorFlow/Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BdgW2N01V8hD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Concatenate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz-8VL-5V8hG"
      },
      "source": [
        "##### **2. Tokenization and Sequence Padding**\n",
        "\n",
        "* Load datasets, encode labels, convert email texts into padded numeric sequences using Tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8hoRudKgV8hG"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "train_df = pd.read_csv(\"group34_train_data_with_clusters.csv\")\n",
        "test_df = pd.read_csv(\"group34_test_data_with_clusters.csv\")\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "train_labels = le.fit_transform(train_df['label'])  # spam:1, ham:0\n",
        "test_labels = le.transform(test_df['label'])\n",
        "\n",
        "# Prepare tokenizer (fit on train)\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(train_df['email'])\n",
        "\n",
        "# Text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['email'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['email'])\n",
        "\n",
        "# Padding sequences\n",
        "max_len = 200\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPZ0gKi7V8hI"
      },
      "source": [
        "##### **3. Bi-LSTM Model Definition**\n",
        "* Define a flexible Bi-LSTM model that optionally incorporates clustering features through concatenation for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hXzN3soxV8hJ"
      },
      "outputs": [],
      "source": [
        "# Function to create Bi-LSTM model\n",
        "def create_model(cluster_feature_dim=0):\n",
        "    input_text = Input(shape=(max_len,))\n",
        "    embedding = Embedding(input_dim=5000, output_dim=128)(input_text)\n",
        "    x = Bidirectional(LSTM(64))(embedding)\n",
        "\n",
        "    if cluster_feature_dim > 0:\n",
        "        input_cluster = Input(shape=(cluster_feature_dim,))\n",
        "        concatenated = Concatenate()([x, input_cluster])\n",
        "        output = Dense(1, activation='sigmoid')(concatenated)\n",
        "        model = Model(inputs=[input_text, input_cluster], outputs=output)\n",
        "    else:\n",
        "        output = Dense(1, activation='sigmoid')(x)\n",
        "        model = Model(inputs=input_text, outputs=output)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **4. Prepare Clustering Features and Configurations**\n",
        "* Perform one-hot encoding on K-Means and hierarchical cluster labels, prepare datasets for each model configuration and set up the StratifiedKFold for cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPqF7_RVV8hJ"
      },
      "outputs": [],
      "source": [
        "# Prepare clustering features\n",
        "cluster_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "train_kmeans_feat = cluster_encoder.fit_transform(train_df[['kmeans_cluster']])\n",
        "test_kmeans_feat = cluster_encoder.transform(test_df[['kmeans_cluster']])\n",
        "\n",
        "train_hier_feat = cluster_encoder.fit_transform(train_df[['hierarchical_cluster']])\n",
        "test_hier_feat = cluster_encoder.transform(test_df[['hierarchical_cluster']])\n",
        "\n",
        "# K-fold Cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store configurations with corresponding features\n",
        "configurations = {\n",
        "    'Baseline Bi-LSTM': (X_train_pad, None, None),\n",
        "    'Bi-LSTM + K-Means': (X_train_pad, train_kmeans_feat, test_kmeans_feat),\n",
        "    'Bi-LSTM + Hierarchical': (X_train_pad, train_hier_feat, test_hier_feat)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **5. Stratified 5-Fold Cross-Validation**\n",
        "* Implement a 5-fold cross-validation strategy for each model configuration, train and validate the models and report classification metrics for each configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1vIjUDKV8hK",
        "outputId": "104b1202-661d-4ef2-894c-915adec87c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Stratified 5-Fold CV: Baseline Bi-LSTM ---\n",
            "\n",
            "Fold 1\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.8769 - loss: 0.2958 - val_accuracy: 0.9822 - val_loss: 0.0562\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9910 - loss: 0.0305 - val_accuracy: 0.9822 - val_loss: 0.0594\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9952 - loss: 0.0175 - val_accuracy: 0.9835 - val_loss: 0.0600\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8667 - loss: 0.3071 - val_accuracy: 0.9822 - val_loss: 0.0592\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9919 - loss: 0.0271 - val_accuracy: 0.9826 - val_loss: 0.0576\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9959 - loss: 0.0147 - val_accuracy: 0.9805 - val_loss: 0.0712\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.8731 - loss: 0.2589 - val_accuracy: 0.9839 - val_loss: 0.0447\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9922 - loss: 0.0282 - val_accuracy: 0.9829 - val_loss: 0.0462\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9946 - loss: 0.0192 - val_accuracy: 0.9855 - val_loss: 0.0470\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8877 - loss: 0.2453 - val_accuracy: 0.9854 - val_loss: 0.0490\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9911 - loss: 0.0304 - val_accuracy: 0.9850 - val_loss: 0.0459\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9958 - loss: 0.0164 - val_accuracy: 0.9872 - val_loss: 0.0474\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.8687 - loss: 0.2593 - val_accuracy: 0.9876 - val_loss: 0.0425\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9918 - loss: 0.0290 - val_accuracy: 0.9854 - val_loss: 0.0448\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9943 - loss: 0.0205 - val_accuracy: 0.9868 - val_loss: 0.0455\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\n",
            "Classification Report for Baseline Bi-LSTM (5-fold CV combined results):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.98      0.98     13236\n",
            "        spam       0.98      0.99      0.99     13736\n",
            "\n",
            "    accuracy                           0.98     26972\n",
            "   macro avg       0.98      0.98      0.98     26972\n",
            "weighted avg       0.98      0.98      0.98     26972\n",
            "\n",
            "\n",
            "--- Stratified 5-Fold CV: Bi-LSTM + K-Means ---\n",
            "\n",
            "Fold 1\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8770 - loss: 0.2759 - val_accuracy: 0.9824 - val_loss: 0.0566\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9904 - loss: 0.0318 - val_accuracy: 0.9848 - val_loss: 0.0519\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9956 - loss: 0.0160 - val_accuracy: 0.9829 - val_loss: 0.0560\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.8685 - loss: 0.2641 - val_accuracy: 0.9813 - val_loss: 0.0584\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9919 - loss: 0.0277 - val_accuracy: 0.9809 - val_loss: 0.0729\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9913 - loss: 0.0278 - val_accuracy: 0.9811 - val_loss: 0.0651\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.8373 - loss: 0.2736 - val_accuracy: 0.9831 - val_loss: 0.0548\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9888 - loss: 0.0390 - val_accuracy: 0.9841 - val_loss: 0.0456\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9919 - loss: 0.0330 - val_accuracy: 0.9820 - val_loss: 0.0520\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.8810 - loss: 0.2925 - val_accuracy: 0.9837 - val_loss: 0.0491\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9920 - loss: 0.0266 - val_accuracy: 0.9848 - val_loss: 0.0457\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9964 - loss: 0.0136 - val_accuracy: 0.9859 - val_loss: 0.0461\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9151 - loss: 0.2458 - val_accuracy: 0.9861 - val_loss: 0.0406\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9906 - loss: 0.0289 - val_accuracy: 0.9885 - val_loss: 0.0371\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9943 - loss: 0.0172 - val_accuracy: 0.9868 - val_loss: 0.0469\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\n",
            "Classification Report for Bi-LSTM + K-Means (5-fold CV combined results):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.98      0.98     13236\n",
            "        spam       0.98      0.99      0.98     13736\n",
            "\n",
            "    accuracy                           0.98     26972\n",
            "   macro avg       0.98      0.98      0.98     26972\n",
            "weighted avg       0.98      0.98      0.98     26972\n",
            "\n",
            "\n",
            "--- Stratified 5-Fold CV: Bi-LSTM + Hierarchical ---\n",
            "\n",
            "Fold 1\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8895 - loss: 0.2399 - val_accuracy: 0.9787 - val_loss: 0.0642\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9906 - loss: 0.0358 - val_accuracy: 0.9848 - val_loss: 0.0478\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9946 - loss: 0.0166 - val_accuracy: 0.9755 - val_loss: 0.0713\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9111 - loss: 0.2409 - val_accuracy: 0.9829 - val_loss: 0.0570\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9904 - loss: 0.0306 - val_accuracy: 0.9837 - val_loss: 0.0576\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9954 - loss: 0.0178 - val_accuracy: 0.9583 - val_loss: 0.1374\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.8725 - loss: 0.2472 - val_accuracy: 0.9835 - val_loss: 0.0471\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9908 - loss: 0.0300 - val_accuracy: 0.9835 - val_loss: 0.0437\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9949 - loss: 0.0196 - val_accuracy: 0.9846 - val_loss: 0.0483\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9014 - loss: 0.2477 - val_accuracy: 0.9841 - val_loss: 0.0492\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9907 - loss: 0.0291 - val_accuracy: 0.9850 - val_loss: 0.0550\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9954 - loss: 0.0162 - val_accuracy: 0.9859 - val_loss: 0.0515\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.8672 - loss: 0.2591 - val_accuracy: 0.9833 - val_loss: 0.0469\n",
            "Epoch 2/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9909 - loss: 0.0288 - val_accuracy: 0.9859 - val_loss: 0.0430\n",
            "Epoch 3/3\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.9957 - loss: 0.0157 - val_accuracy: 0.9803 - val_loss: 0.0633\n",
            "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
            "\n",
            "Classification Report for Bi-LSTM + Hierarchical (5-fold CV combined results):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.97      0.98     13236\n",
            "        spam       0.97      0.99      0.98     13736\n",
            "\n",
            "    accuracy                           0.98     26972\n",
            "   macro avg       0.98      0.98      0.98     26972\n",
            "weighted avg       0.98      0.98      0.98     26972\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Perform StratifiedKFold cross-validation for each configuration\n",
        "for config_name, (text_data, cluster_data, test_cluster_data) in configurations.items():\n",
        "    print(f\"\\n--- Stratified 5-Fold CV: {config_name} ---\")\n",
        "\n",
        "    all_val_preds = []\n",
        "    all_val_actuals = []\n",
        "    fold = 1\n",
        "    for train_index, val_index in skf.split(text_data, train_labels):\n",
        "        print(f\"\\nFold {fold}\")\n",
        "        X_text_train, X_text_val = text_data[train_index], text_data[val_index]\n",
        "        y_train_fold, y_val_fold = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "        # Prepare clustering data if possible\n",
        "        if cluster_data is not None:\n",
        "            X_cluster_train, X_cluster_val = cluster_data[train_index], cluster_data[val_index]\n",
        "            model = create_model(cluster_feature_dim=cluster_data.shape[1])\n",
        "            model.fit(\n",
        "                [X_text_train, X_cluster_train], y_train_fold,\n",
        "                epochs=3, batch_size=64,\n",
        "                validation_data=([X_text_val, X_cluster_val], y_val_fold)\n",
        "            )\n",
        "            val_pred = (model.predict([X_text_val, X_cluster_val]) > 0.5).astype(\"int32\")\n",
        "        else:\n",
        "            model = create_model()\n",
        "            model.fit(\n",
        "                X_text_train, y_train_fold,\n",
        "                epochs=3, batch_size=64,\n",
        "                validation_data=(X_text_val, y_val_fold)\n",
        "            )\n",
        "            val_pred = (model.predict(X_text_val) > 0.5).astype(\"int32\")\n",
        "\n",
        "        all_val_preds.extend(val_pred.flatten())\n",
        "        all_val_actuals.extend(y_val_fold)\n",
        "        fold += 1\n",
        "\n",
        "    # Classification report after cross-validation for each configuration\n",
        "    print(f\"\\nClassification Report for {config_name} (5-fold CV combined results):\")\n",
        "    print(classification_report(all_val_actuals, all_val_preds, target_names=le.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **6. Final Explicit Evaluation on Unseen Test Set**\n",
        "* Retrain each model configuration explicitly on the full training set, evaluate them on an independent test set, and provide detailed classification metrics along with insightful extreme-error analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqP3fNzOV8hL",
        "outputId": "6ab655f6-a8b2-4c87-ec82-fb958ffc22f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========== FINAL EVALUATION ON UNSEEN TEST SET ==========\n",
            "\n",
            "\n",
            "=== Final Classification Report: Baseline Bi-LSTM ===\n",
            "Epoch 1/3\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.8858 - loss: 0.2353 - val_accuracy: 0.9874 - val_loss: 0.0416\n",
            "Epoch 2/3\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9919 - loss: 0.0303 - val_accuracy: 0.9889 - val_loss: 0.0346\n",
            "Epoch 3/3\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.9946 - loss: 0.0181 - val_accuracy: 0.9893 - val_loss: 0.0304\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.99      0.99      3309\n",
            "        spam       0.99      0.99      0.99      3434\n",
            "\n",
            "    accuracy                           0.99      6743\n",
            "   macro avg       0.99      0.99      0.99      6743\n",
            "weighted avg       0.99      0.99      0.99      6743\n",
            "\n",
            "\n",
            "Insightful Analysis of Extreme Errors for Baseline Bi-LSTM (Top 10 examples):\n",
            "                                                 email  actual  prediction\n",
            "38   subject reply inquiry hjl turn days paypal sig...       1           0\n",
            "147  subject fw whose needs perfect proprietary hus...       0           1\n",
            "259  subject fw quips remember amateurs built ark p...       0           1\n",
            "299  subject aluum llgra caalls levltrra xana loraa...       1           0\n",
            "426  subject enron mentions usa u stocks slip fed r...       0           1\n",
            "476  subject external counterparty external user lo...       0           1\n",
            "616  subject introducing new iijournals online inst...       0           1\n",
            "691  subject fw computers happy holidays bonnie hit...       0           1\n",
            "714  subject correction first delivery cody read cu...       0           1\n",
            "741  subject positions available microsoft research...       1           0\n",
            "\n",
            "=== Final Classification Report: Bi-LSTM + K-Means ===\n",
            "Epoch 1/3\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8652 - loss: 0.2559 - val_accuracy: 0.9904 - val_loss: 0.0376\n",
            "Epoch 2/3\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9892 - loss: 0.0361 - val_accuracy: 0.9900 - val_loss: 0.0322\n",
            "Epoch 3/3\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.9960 - loss: 0.0153 - val_accuracy: 0.9807 - val_loss: 0.0559\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.97      0.98      3309\n",
            "        spam       0.97      0.99      0.98      3434\n",
            "\n",
            "    accuracy                           0.98      6743\n",
            "   macro avg       0.98      0.98      0.98      6743\n",
            "weighted avg       0.98      0.98      0.98      6743\n",
            "\n",
            "\n",
            "Insightful Analysis of Extreme Errors for Bi-LSTM + K-Means (Top 10 examples):\n",
            "                                                 email  actual  prediction\n",
            "24   subject inch v goodmorning need another inch v...       0           1\n",
            "38   subject reply inquiry hjl turn days paypal sig...       1           0\n",
            "147  subject fw whose needs perfect proprietary hus...       0           1\n",
            "164  subject personal trainers like time read reall...       0           1\n",
            "188  subject attack powerpoint installed go http of...       0           1\n",
            "259  subject fw quips remember amateurs built ark p...       0           1\n",
            "313  subject hi hello mister bill quick note say so...       0           1\n",
            "426  subject enron mentions usa u stocks slip fed r...       0           1\n",
            "476  subject external counterparty external user lo...       0           1\n",
            "493  subject news alert wall street research otc sp...       1           0\n",
            "\n",
            "=== Final Classification Report: Bi-LSTM + Hierarchical ===\n",
            "Epoch 1/3\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9309 - loss: 0.2716 - val_accuracy: 0.9855 - val_loss: 0.0445\n",
            "Epoch 2/3\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9909 - loss: 0.0308 - val_accuracy: 0.9904 - val_loss: 0.0334\n",
            "Epoch 3/3\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9953 - loss: 0.0173 - val_accuracy: 0.9896 - val_loss: 0.0332\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.98      0.99      3309\n",
            "        spam       0.98      0.99      0.99      3434\n",
            "\n",
            "    accuracy                           0.99      6743\n",
            "   macro avg       0.99      0.99      0.99      6743\n",
            "weighted avg       0.99      0.99      0.99      6743\n",
            "\n",
            "\n",
            "Insightful Analysis of Extreme Errors for Bi-LSTM + Hierarchical (Top 10 examples):\n",
            "                                                 email  actual  prediction\n",
            "147  subject fw whose needs perfect proprietary hus...       0           1\n",
            "164  subject personal trainers like time read reall...       0           1\n",
            "188  subject attack powerpoint installed go http of...       0           1\n",
            "259  subject fw quips remember amateurs built ark p...       0           1\n",
            "269  subject ds need one place congresswoman one re...       1           0\n",
            "284  subject eletrobolt opic press release joe got ...       0           1\n",
            "426  subject enron mentions usa u stocks slip fed r...       0           1\n",
            "616  subject introducing new iijournals online inst...       0           1\n",
            "691  subject fw computers happy holidays bonnie hit...       0           1\n",
            "741  subject positions available microsoft research...       1           0\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------\n",
        "# Final evaluation for each configuration clearly:\n",
        "print(\"\\n========== FINAL EVALUATION ON UNSEEN TEST SET ==========\\n\")\n",
        "\n",
        "for config_name, (text_data, cluster_data, test_cluster_data) in configurations.items():\n",
        "    print(f\"\\n=== Final Classification Report: {config_name} ===\")\n",
        "\n",
        "    # Train on full training data\n",
        "    if cluster_data is not None:\n",
        "        model = create_model(cluster_feature_dim=cluster_data.shape[1])\n",
        "        model.fit(\n",
        "            [text_data, cluster_data], train_labels,\n",
        "            epochs=3, batch_size=64, validation_split=0.1\n",
        "        )\n",
        "        predictions = (model.predict([X_test_pad, test_cluster_data]) > 0.5).astype(\"int32\")\n",
        "    else:\n",
        "        model = create_model()\n",
        "        model.fit(\n",
        "            text_data, train_labels,\n",
        "            epochs=3, batch_size=64, validation_split=0.1\n",
        "        )\n",
        "        predictions = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "\n",
        "    # Print final classification report\n",
        "    print(classification_report(test_labels, predictions, target_names=le.classes_))\n",
        "\n",
        "    # Extreme error analysis\n",
        "    error_analysis_df = test_df.copy()\n",
        "    error_analysis_df['prediction'] = predictions.flatten()\n",
        "    error_analysis_df['actual'] = test_labels\n",
        "    extreme_errors = error_analysis_df[error_analysis_df['prediction'] != error_analysis_df['actual']]\n",
        "\n",
        "    print(f\"\\nInsightful Analysis of Extreme Errors for {config_name} (Top 10 examples):\")\n",
        "    print(extreme_errors[['email', 'actual', 'prediction']].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOyhdNugV8hQ"
      },
      "source": [
        "##### **7. Results**\n",
        "The experiments evaluated 3 configurations using a Bi-LSTM model with 5-fold cross-validation and an test set.\n",
        "\n",
        "Cross-validation Results:\n",
        "\n",
        "* Baseline Bi-LSTM:\n",
        "\n",
        "    * Accuracy ranged between 98.0–98.7%, with loss consistently low (0.0147–0.0205).\n",
        "\n",
        "    * Precision, recall, and F1-score were high for both classes (ham: 99% precision, 98% recall, 98% F1; spam: 98% precision, 99% recall, 99% F1).\n",
        "\n",
        "* Bi-LSTM + K-Means:\n",
        "\n",
        "    * Similar accuracy (98.1–98.7%) and low loss (0.0136–0.0330) across folds.\n",
        "\n",
        "    * Kept high metrics with slight variation (ham: 99% precision, 98% recall, 98% F1; spam: 98% precision, 99% recall, 98% F1).\n",
        "\n",
        "* Bi-LSTM + Hierarchical:\n",
        "\n",
        "    * Accuracy similarly ranged around 98%, with occasional low loss (0.0157–0.0358).\n",
        "\n",
        "    * Consistent high performance (ham: 99% precision, 97% recall, 98% F1; spam: 97% precision, 99% recall, 98% F1).\n",
        "\n",
        "Final Evaluation on Unseen Test Set:\n",
        "\n",
        "* Baseline Bi-LSTM:\n",
        "\n",
        "    * Achieved 99% accuracy, very low loss (0.0181), and near-perfect scores (ham and spam: 99% precision, 99% recall, 99% F1).\n",
        "\n",
        "* Bi-LSTM + K-Means:\n",
        "\n",
        "    * Accuracy slightly lower (98%), with low loss (0.0153).\n",
        "\n",
        "    * Precision and recall slightly reduced for ham (99% precision, 97% recall, 98% F1), and for spam (97% precision, 99% recall, 98% F1).\n",
        "\n",
        "* Bi-LSTM + Hierarchical:\n",
        "\n",
        "    * Strong performance with 99% accuracy and lowest loss (0.0173), matching the baseline closely.\n",
        "\n",
        "    * Great precision, recall, and F1-score for both classes (ham: 99% precision, 98% recall, 99% F1; spam: 98% precision, 99% recall, 99% F1).\n",
        "\n",
        "Extreme Error Analysis:\n",
        "\n",
        "Analyzing the top misclassifications revealed certain challenging emails consistently misclassified across configurations, indicating subtle linguistic ambiguities rather than model weakness.\n",
        "\n",
        "Summary:\n",
        "\n",
        "Overall, all configurations exhibited excellent predictive performance. The hierarchical clustering features performed slightly better than K-Means, but the baseline model already performed as well, emphasizing that clustering features may not add much value compared to just using the baseline model, at least for this dataset."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
